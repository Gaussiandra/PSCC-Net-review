# [PSCC-Net](https://arxiv.org/pdf/2103.10596v2.pdf)

## Постановка задачи

Авторы статьи решают задачу image manipulation detection and localization, где для предложенной картинки нужно определить, есть ли изменения вида splicing, copy-move, removal и, если есть, вывести маску, где эти изменения применены.  

Пример картинок с изменением и соответствующими масками.  
![dataset example](https://user-images.githubusercontent.com/34653515/230970857-85ba2663-cc93-47f4-949a-c859089f36e1.png)

## Верхнеуровневое описание

Исследователи реализуют архитектуру сети на основе HRNet и предложенного SCCM модуля для нахождения spatial и channel-wise корреляций. Сеть состоит из  Top-down и Bottom-up проходов. В первом проходе из исходной картинки извлекаются признаки четырёх разных размерностей с помощью HRNet. Далее во втором проходе каждый из четырёх наборов признаков пропускается через SCCM и Detection Head, благодаря чему удаётся оценить вероятность того, что картинка была изменена, и узнать маску предполагаемого изменения.

Архитектура PSCC-Net
![net](https://user-images.githubusercontent.com/34653515/230971013-f4a64a06-d248-4893-9288-303e233780a3.png)

Полученная архитектура работает и обучается быстрее предшественников и при этом станосится SOTA подходом в задачах детекции и локализации.

## Детальное описание

Исходная картинка пропускается через HRNetV2p-W18, благодаря чему получается четыре набора признаков размерностей $\displaystyle\frac{H}{2^i} \times \displaystyle\frac{W}{2^i} \times 2^iC, \ где \ i = \{0, 1, 2, 3\}$. Затем решаются задачи детекции с помощью Detection Head и локализации с помощью SCCM. Сам процесс локализации заключается в получении маски изменённой части картинки ($M_1$). Она получается из HRNet признаков ($F_i$), как описано в цитате из статьи ниже.

![image](https://user-images.githubusercontent.com/34653515/230973598-363a3baf-fe2b-4257-a03b-d7792e88f1c3.png)

### SCCM

Основное нововведение статьи состоит в предложенном способе находить spatial и channel-wise корреляции, а затем объединять их. 

Прежде всего к признаками применяется функция $h$, которая уменьшает их размерность(см. фото ниже), что позволяет снизить расход памяти и время работы сети. В данном случае $r$ берётся равным четырём.

![image](https://user-images.githubusercontent.com/34653515/230973815-1323d8f3-593a-4d3d-b10d-42541795fb03.png)

Далее применяются $1 \times 1$ свёртки $g, \theta, \phi$ для преобразования $h(X)$.

![image](https://user-images.githubusercontent.com/34653515/230974133-4e0a1be4-c606-4b34-9c07-7d60678d174b.png)

После чего происходит вычисление spatial and channel-wise attentions и их upsampling($h^{-1}$).

![Ys](https://user-images.githubusercontent.com/34653515/230971644-b0f865c3-c95f-4584-8123-650142c1f46f.png)
![Yc](https://user-images.githubusercontent.com/34653515/230971657-736fa6e5-a67b-4d11-a6da-3383645ae304.png)

В конце концов вычисляются residuals и искомая маска.

![image](https://user-images.githubusercontent.com/34653515/230974394-5ffff672-732c-4c0e-9cc5-c3c0ad472bf2.png)

Обучение происходит на binary cross-entropy loss, который учитывает качество детекции и всех полученных масок.

![loss](https://user-images.githubusercontent.com/34653515/230971732-0f456ffd-9aac-4602-8097-0f6d3a00b795.png)

### Данные и подробности обучения

Обучение происходило на 116,583 картинках с splicing class,
100,000 с copy-move class, 78,246 с removal class, и 81,910 фотограций без изменений. В статье также подробно описан способ генерации этих данных для обучения. 

На вход подавались картинки размером 256x256, обучение просходило с batch size = 10 и learning rate 2e-4 с уменьшением вдвое каждые пять эпох(всего их 25) на Nvidia GTX 1080Ti. Всего 2M параметров на HRNet(бралась предобученная на ImageNet), 0,9M на Detection Head и 0,7M на остальную часть Bottom-up пайплайна.

## Результаты и метрики

В качестве метрик в статье используют F1 и AUC и измеряют качество для задач локализации и детекции отдельно. Кроме этого, для задачи локализации ещё делают дообучение под домен датасета, на котором считается оценка.

Оригинальный PSCC-Net показывает лучшее качество на датасетах Columbia, CASIA, NIST16 и IMD20. На Coverage он оказывается вторым(table II). Дообученная модель стала лучшей на датасетах Coverage, CASIA, NIST16(table III).

![localization metrics](https://user-images.githubusercontent.com/34653515/230971797-769fbd7c-9a74-4602-af3e-d6d60c637b5c.png)

В задаче детекции PSCC-Net также показала лучшие результаты среди других моделей.

![detection metrics](https://user-images.githubusercontent.com/34653515/230971818-24610d65-4a85-4058-b83c-696d475c85cc.png)

Все эти результаты приводят исследователей к выводу о том, что их модель становится SOTA подходом на момент выхода статьи.

## Идеи для улучшения

1. Взять HRNet с большим числом параметров, чем в предложенной статье. Например HRNet W64(вместо W18, как в статье).
2. Увеличить число параметров в SCCM блоке, уменьшив параметр $r$ до двух. Эта идея позволит уменьшить проблему боттленека(про которую авторы даже не писали) во время применения функции $h$. Сейчас их опасение про недостаток видеопамяти менее актуально ввиду появления всё более новых видеокарт.
3. Попробовать взять другой энкодер (например EfficientNet или какой-нибудь ViT) и отказаться от применения четырёх разных слоёв для генерации масок, вместо этого использовать только один SCCM. Применение четырёх разных слоёв выглядит довольно нецелостно и у меня есть интуитивное ощущение, что эту часть можно оптимизировать. Кроме этого, мой вариант должен лучше распараллеливаться.
4. Можно ускорить процесс обучения и инференса модели, если использовать только две или три маски вместо четырёх. В статье(Table V) показано, что качество от Mask 3 к PSCC-Net растёт незначительно, но при этом время исполнения возрастает на 25%.
